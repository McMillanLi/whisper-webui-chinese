import os
import json
import torch
import whisper
import gradio as gr

# æ¨¡å‹ç¼“å­˜ç›®å½•è®¾ä¸ºé¡¹ç›®å†…æ–‡ä»¶å¤¹
os.environ["XDG_CACHE_HOME"] = os.path.join(os.getcwd(), "models")

CONFIG_PATH = "config.json"
default_config = {
    "model_size": "base",
    "save_formats": [],
    "save_dir": "",
    "device": "CPU"
}

def load_config():
    if os.path.exists(CONFIG_PATH):
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return default_config.copy()

def save_config(cfg):
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(cfg, f, indent=2, ensure_ascii=False)

def on_model_change(choice):
    cfg = load_config()
    cfg["model_size"] = choice
    save_config(cfg)

def on_format_change(choices):
    cfg = load_config()
    cfg["save_formats"] = choices
    save_config(cfg)

def on_device_change(choice):
    cfg = load_config()
    cfg["device"] = choice
    save_config(cfg)

def on_save_dir_confirm(new_path):
    cfg = load_config()
    cfg["save_dir"] = new_path
    save_config(cfg)
    return f"ä¿å­˜ç›®å½•è®¾ç½®ä¸ºï¼š{new_path}"

def open_save_folder():
    cfg = load_config()
    path = cfg.get("save_dir", "")
    if os.path.isdir(path):
        os.startfile(path)
        return f"æ‰“å¼€ç›®å½•ï¼š{path}"
    else:
        return "âŒ ä¿å­˜ç›®å½•æ— æ•ˆæˆ–ä¸å­˜åœ¨"

def format_srt_time(seconds):
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds - int(seconds)) * 1000)
    return f"{hours:02}:{minutes:02}:{secs:02},{millis:03}"

def save_transcription(result, audio_path, output_dir, formats):
    filename = os.path.splitext(os.path.basename(audio_path))[0]
    os.makedirs(output_dir, exist_ok=True)

    if "txt" in formats:
        with open(os.path.join(output_dir, f"{filename}.txt"), "w", encoding="utf-8") as f:
            f.write(result["text"])

    if "json" in formats:
        with open(os.path.join(output_dir, f"{filename}.json"), "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

    if "srt" in formats:
        with open(os.path.join(output_dir, f"{filename}.srt"), "w", encoding="utf-8") as f:
            for i, segment in enumerate(result["segments"]):
                f.write(f"{i+1}\n")
                start = format_srt_time(segment["start"])
                end = format_srt_time(segment["end"])
                text = segment["text"].strip()
                f.write(f"{start} --> {end}\n{text}\n\n")

    if "vtt" in formats:
        with open(os.path.join(output_dir, f"{filename}.vtt"), "w", encoding="utf-8") as f:
            f.write("WEBVTT\n\n")
            for segment in result["segments"]:
                start = format_srt_time(segment["start"])
                end = format_srt_time(segment["end"])
                text = segment["text"].strip()
                f.write(f"{start} --> {end}\n{text}\n\n")

    if "tsv" in formats:
        with open(os.path.join(output_dir, f"{filename}.tsv"), "w", encoding="utf-8") as f:
            f.write("start\tend\ttext\n")
            for segment in result["segments"]:
                f.write(f"{segment['start']}\t{segment['end']}\t{segment['text'].strip()}\n")

# ç¼“å­˜æ¨¡å‹å¯¹è±¡
loaded_models = {}

def get_model():
    cfg = load_config()
    device = "cuda" if cfg["device"] == "GPU" and torch.cuda.is_available() else "cpu"
    model_key = f"{cfg['model_size']}-{device}"
    if model_key not in loaded_models:
        model = whisper.load_model(cfg["model_size"])
        model.to(device)
        loaded_models[model_key] = model
    return loaded_models[model_key], device

def transcribe(audio_file):
    if not audio_file:
        return "è¯·ä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚"

    cfg = load_config()
    model, _ = get_model()
    result = model.transcribe(audio_file, language="zh")

    if cfg["save_formats"] and cfg["save_dir"]:
        save_transcription(result, audio_file, cfg["save_dir"], cfg["save_formats"])

    return result["text"]

def batch_transcribe(folder_path):
    if not os.path.isdir(folder_path):
        return "âŒ ç›®å½•æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„è·¯å¾„"

    cfg = load_config()
    model, _ = get_model()
    exts = [".mp3", ".wav", ".m4a", ".flac", ".ogg"]
    results = []
    files = [f for f in os.listdir(folder_path) if os.path.splitext(f)[1].lower() in exts]

    if not files:
        return "âš ï¸ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰éŸ³é¢‘æ–‡ä»¶"

    for f in files:
        path = os.path.join(folder_path, f)
        try:
            result = model.transcribe(path, language="zh")
            if cfg["save_formats"] and cfg["save_dir"]:
                save_transcription(result, path, cfg["save_dir"], cfg["save_formats"])
            results.append(f"âœ… æˆåŠŸï¼š{f}")
        except Exception as e:
            results.append(f"âŒ å¤±è´¥ï¼š{f}ï¼ŒåŸå› ï¼š{str(e)}")

    return "\n".join(results)

# ---------- æ„å»ºç•Œé¢ ----------
cfg = load_config()

with gr.Blocks(title="Whisper ä¸­æ–‡è½¬å†™ WebUI") as demo:
    gr.Markdown("## ğŸ™ Whisper ä¸­æ–‡è½¬å†™ç•Œé¢")

    with gr.Row():
        # å·¦ä¾§è®¾ç½®åŒº
        with gr.Column(scale=1):
            gr.Markdown("### âš™ï¸ è®¾ç½®")

            model_size = gr.Radio(["tiny", "base", "small", "medium", "large"],
                                  label="æ¨¡å‹å¤§å°", value=cfg["model_size"])
            model_size.change(fn=on_model_change, inputs=model_size)

            save_formats = gr.CheckboxGroup(["txt", "srt", "vtt", "json", "tsv"],
                                            label="ä¿å­˜æ ¼å¼", value=cfg["save_formats"])
            save_formats.change(fn=on_format_change, inputs=save_formats)

            device_select = gr.Radio(["CPU", "GPU"], label="è¿è¡Œè®¾å¤‡", value=cfg["device"])
            device_select.change(fn=on_device_change, inputs=device_select)

            gr.Markdown("#### ğŸ“ ä¿å­˜ç›®å½•")
            save_dir_input = gr.Textbox(value=cfg["save_dir"], label="è·¯å¾„")
            confirm_btn = gr.Button("âœ… ç¡®è®¤ä¿å­˜ç›®å½•")
            open_folder_btn = gr.Button("ğŸ“‚ æ‰“å¼€ä¿å­˜ç›®å½•")
            save_dir_status = gr.Textbox(value="", label="çŠ¶æ€", interactive=False)

            confirm_btn.click(fn=on_save_dir_confirm, inputs=save_dir_input, outputs=save_dir_status)
            open_folder_btn.click(fn=open_save_folder, outputs=save_dir_status)

        # å³ä¾§è¾“å‡ºåŒºï¼šæ ‡ç­¾é¡µ
        with gr.Column(scale=2):
            with gr.Tabs():
                with gr.Tab("ğŸ™ å•æ–‡ä»¶è½¬å†™"):
                    audio_input = gr.Audio(type="filepath", label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
                    transcribe_btn = gr.Button("å¼€å§‹è½¬å†™")
                    result_text = gr.Textbox(label="è½¬å†™ç»“æœ", lines=10)
                    transcribe_btn.click(fn=transcribe, inputs=audio_input, outputs=result_text)

                with gr.Tab("ğŸ“‚ æ‰¹é‡è½¬å†™"):
                    folder_input = gr.Textbox(label="è¾“å…¥éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„")
                    batch_btn = gr.Button("å¼€å§‹æ‰¹é‡è½¬å†™")
                    batch_output = gr.Textbox(label="æ‰¹é‡è½¬å†™çŠ¶æ€", lines=15)
                    batch_btn.click(fn=batch_transcribe, inputs=folder_input, outputs=batch_output)

# å¯åŠ¨
if __name__ == "__main__":
    demo.launch()
